{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ezodf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue from each region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at revenue from each region. We've got this data from here: https://www.ons.gov.uk/economy/governmentpublicsectorandtaxes/publicsectorfinance/articles/countryandregionalpublicsectorfinances/2016to2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = pd.read_excel('input/b794db89.xls', skiprows=3)\n",
    "contributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(contributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not interested in revenue per person per region, so we'll remove these figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = contributions.drop(['Unnamed: 4', '2014/15.1', '2015/16.1', ' 2016/17.1'], axis=1)\n",
    "contributions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the figures that divide noth sea oil by population rather than by geography, but it doesn't make much difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = contributions[16:29].copy()\n",
    "contributions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spend on the EU in the 2016/17 tax year was 13.8bn, not including the rebate, which we have ignored here as it is paid straight back. As a % of spending, this is 1.69%. As a proportion of revenue, this is 1.90%, but after reflection I think the 1.69% figure is the right one to use, as it is reflective of the proportion of our income that we spend on the EU, the other 0.21% is borrowed. (figures from https://www.ons.gov.uk/economy/governmentpublicsectorandtaxes/publicsectorfinance/articles/theukcontributiontotheeubudget/2017-10-31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions['EU_funding_2016'] = contributions[' 2016/17']*0.0169\n",
    "contributions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAP data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAP data is all at outcode level, so we will need to translate from outcode, where we have the investment figures, to NUTS1 region, where we have the tax figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the CAP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cap_by_area = pd.concat([\n",
    "    pd.read_pickle('../cap/output/cap_by_area_{}.pkl.gz'.format(year))\n",
    "    for year in range(2016, 2017)\n",
    "])\n",
    "raw_cap_by_area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the link from NUTS data to postcode - this is at NUTS3 level, but the first 3 digits of the NUTS3 code are the NUTS1 code. We'll clean the data and find the postcode area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts = pd.read_csv('input/pc2018_uk_NUTS-2016_v1.0.zip', sep=';')\n",
    "nuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts = nuts.applymap(lambda x: x.replace(\"'\", ''))\n",
    "nuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts['postcode_area'] = \\\n",
    "   nuts['CODE'].str.replace(r'^([A-Z]{1,2}).+$', r'\\1')\n",
    "nuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts['nuts_1'] = \\\n",
    "   nuts['NUTS3'].str.replace(r'^([A-Z]{1,3}).+$', r'\\1')\n",
    "nuts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is overlap with the same postcode area in different NUTS1 areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group = nuts.groupby('nuts_1')['postcode_area'].unique()\n",
    "group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = pd.DataFrame.from_dict(group)\n",
    "group_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKC'][np.isin(group_df.postcode_area['UKC'], group_df.postcode_area['UKD'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKC'][np.isin(group_df.postcode_area['UKC'], group_df.postcode_area['UKE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKD'][np.isin(group_df.postcode_area['UKD'], group_df.postcode_area['UKE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKD'][np.isin(group_df.postcode_area['UKD'], group_df.postcode_area['UKF'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKD'][np.isin(group_df.postcode_area['UKD'], group_df.postcode_area['UKG'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKE'][np.isin(group_df.postcode_area['UKE'], group_df.postcode_area['UKF'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out, even Scotland had crossovers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKM'][np.isin(group_df.postcode_area['UKM'], group_df.postcode_area['UKC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKM'][np.isin(group_df.postcode_area['UKM'], group_df.postcode_area['UKD'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried this but it didn't work - saving in case I want to come back to it\n",
    "\n",
    "for nuts_1 in group_df:\n",
    "    print(group_df.iloc[nuts_1]['nuts_1'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at Wales to see if there is any crossover with its bordering regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKL'][np.isin(group_df.postcode_area['UKL'], group_df.postcode_area['UKD'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKL'][np.isin(group_df.postcode_area['UKL'], group_df.postcode_area['UKG'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.postcode_area['UKL'][np.isin(group_df.postcode_area['UKL'], group_df.postcode_area['UKK'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pretty sure Northern Ireland just has one postocde, which should be unique, let's check there is a single postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cap_by_area[raw_cap_by_area['postcode_area'] == 'BT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Northern Ireland as an example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothern Ireland has a simple mapping of a single postcode so we can try out the data with it, to see what sorts of figures we're looking at. They also have a really high amount of CAP, so if they're not a net receiver then no one is likely to be!\n",
    "\n",
    "So, in 2016, Northern Ireland gave £281,689,000  and received £283,568,147 in CAP if we're using the 1.69% figure, then they are a net receiver already. However, it'll be interesting to see how much higher we can get it, and if we can get past 1.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NI ESIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at ESIF first, and find the total amount spent in Northern Ireland in 2016. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_postcode_area(df):\n",
    "    df['postcode_area'] = df['postcode'].str.replace(r'^([A-Z]{1,2}).+$', r'\\1')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esif = pd.concat([\n",
    "    pd.read_pickle('../esif/output/esif_{}.pkl.gz'.format(dataset))\n",
    "    for dataset in ['ni_2014_2020']\n",
    "], sort=True)\n",
    "add_postcode_area(esif)\n",
    "esif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_annual_sum(df, keys, column):\n",
    "    def reweight(row):\n",
    "        # create timeseries from start to end\n",
    "        days = pd.date_range(row.start_date, row.end_date, closed='left')\n",
    "        daily = pd.DataFrame({\n",
    "            'year_start': days,\n",
    "            column: row[column] / days.shape[0]\n",
    "        })\n",
    "        annual = daily.resample('AS', on='year_start').sum()\n",
    "        for key in keys:\n",
    "            annual[key] = row[key]\n",
    "        return annual\n",
    "    result = pd.concat(list(df.apply(reweight, axis=1)))\n",
    "    result.reset_index(inplace=True)\n",
    "    result['year'] = result.year_start.apply(lambda x: x.year)\n",
    "    result.drop('year_start', axis=1, inplace=True)\n",
    "    return result[['year'] + keys + [column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fund_annual_totals(annual, column):\n",
    "    annual_total = annual.groupby(['funds', 'year'])[column].sum()\n",
    "    annual_total = annual_total.reset_index()\n",
    "    annual_total.rename(columns={column: 'total'}, inplace=True)\n",
    "    return annual_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esif_annual = find_annual_sum(esif, ['funds', 'postcode_area', 'my_eu_id'], 'eu_investment')\n",
    "esif_annual_total = find_fund_annual_totals(esif_annual, 'eu_investment')\n",
    "esif_annual_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esif_annual_total[esif_annual['year'] == 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so this is £21,215,000 - adding it to the £283,568,147 we already have, that's £304,783,147 - still not quite up to 1.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Horizon 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2020_organizations = pd.read_pickle('../cordis/output/h2020_organizations.pkl.gz')\n",
    "h2020_projects = pd.read_pickle('../cordis/output/h2020_projects.pkl.gz')\n",
    "h2020 = pd.merge(\n",
    "    h2020_projects, h2020_organizations,\n",
    "    left_on='rcn', right_on='project_rcn', validate='1:m'\n",
    ")\n",
    "add_postcode_area(h2020)\n",
    "h2020['my_eu_id'] = 'h2020_' + h2020.project_rcn.astype('str') + '_' + h2020.organization_id.astype('str')\n",
    "h2020['funds'] = 'H2020'\n",
    "h2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_missing_cordis_contributions():\n",
    "    c = h2020.contribution_eur.copy()\n",
    "    c[c.isna()] = h2020.max_contribution_eur[c.isna()] / h2020.num_organizations[c.isna()]\n",
    "    h2020['estimated_contribution_eur'] = c\n",
    "estimate_missing_cordis_contributions()\n",
    "h2020[h2020.contribution_eur.isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2020['contribution_gbp'] = h2020.contribution_eur * h2020.eur_gbp\n",
    "h2020['estimated_contribution_gbp'] = h2020.estimated_contribution_eur * h2020.eur_gbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2020_ni = h2020[h2020['postcode_area'] == 'BT'].copy()\n",
    "h2020_ni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2020_ni.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2020_ni_annual = find_annual_sum(h2020_ni, ['postcode_area', 'my_eu_id', 'funds'], 'estimated_contribution_gbp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " h2020_ni_annual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fund_annual_totals(annual, column):\n",
    "    annual_total = annual.groupby(['funds', 'year'])[column].sum()\n",
    "    annual_total = annual_total.reset_index()\n",
    "    annual_total.rename(columns={column: 'total'}, inplace=True)\n",
    "    return annual_total\n",
    "cordis_annual_total = find_fund_annual_totals(h2020_ni_annual, 'estimated_contribution_gbp')\n",
    "cordis_annual_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's £7,961,557, so now we're at £312,744,704 in total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erasmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erasmus_organisations = pd.read_pickle('../erasmus/output/erasmus_mobility_organisations.pkl.gz')\n",
    "erasmus_projects = pd.read_pickle('../erasmus/output/erasmus_mobility_projects.pkl.gz')\n",
    "erasmus = pd.merge(erasmus_projects, erasmus_organisations, on='project_identifier', validate='1:m')\n",
    "erasmus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_postcode_area(erasmus)\n",
    "assert erasmus.funds.unique().shape[0] == 1\n",
    "erasmus['funds'] = 'Erasmus'\n",
    "erasmus['my_eu_id'] = \\\n",
    "    'erasmus_' + erasmus.project_identifier + '_' + \\\n",
    "    erasmus.partner_number.apply('{:.0f}'.format).\\\n",
    "    str.replace('nan', 'coordinator', regex=False)\n",
    "assert erasmus.shape[0] == erasmus.my_eu_id.unique().shape[0]\n",
    "erasmus.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[erasmus.shape[0], erasmus.max_contribution_eur.isna().sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erasmus['estimated_contribution_eur'] = \\\n",
    "    erasmus.max_contribution_eur / erasmus.num_organisations\n",
    "erasmus['estimated_contribution_gbp'] = erasmus.estimated_contribution_eur * erasmus.eur_gbp\n",
    "erasmus['max_contribution_gbp'] = erasmus.max_contribution_eur * erasmus.eur_gbp\n",
    "erasmus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erasmus['start_date'] = pd.to_datetime(erasmus.call_year.apply(str) + '-01-01')\n",
    "erasmus['end_date'] = pd.to_datetime(erasmus.call_year.apply(str) + '-12-31')\n",
    "erasmus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erasmus_annual = find_annual_sum(erasmus, ['funds', 'postcode_area', 'my_eu_id'], 'estimated_contribution_gbp')\n",
    "erasmus_annual_total = find_fund_annual_totals(erasmus_annual, 'estimated_contribution_gbp')\n",
    "erasmus_annual_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fund_annual_area_totals(annual, column):\n",
    "    annual_total = annual.groupby(['funds', 'postcode_area', 'year'])[column].sum()\n",
    "    annual_total = annual_total.reset_index()\n",
    "    annual_total.rename(columns={column: 'total'}, inplace=True)\n",
    "    return annual_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erasmus_annual_area_total = find_fund_annual_area_totals(erasmus_annual, 'estimated_contribution_gbp')\n",
    "erasmus_annual_area_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erasmus_annual_area_total[erasmus_annual_area_total.postcode_area == 'BT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for 2016 that is £6,001,891, which takes our total to £318,746,595 - well over the 1.9% figure. Whichever way you look at it, NI is a net receiver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Postcode area Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how many postcodes are in each NUTS area, so we can see what % of CAP funding we will need to put in each region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_count = pd.DataFrame(nuts.groupby(['nuts_1','postcode_area']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_count = group_count.reset_index()\n",
    "group_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_count = nuts.groupby(['postcode_area']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_count = pd.DataFrame.from_dict(data = postcode_count)\n",
    "postcode_count = postcode_count.reset_index()\n",
    "postcode_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_merge = pd.merge(group_count, postcode_count, how='outer', on='postcode_area')\n",
    "postcode_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode_merge['percent_postcodes'] = postcode_merge['0_x']/postcode_merge['0_y']\n",
    "postcode_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAP per region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have number of postcodes per region, let's look at cap funding per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_per_postcode = pd.merge(postcode_merge, raw_cap_by_area, how='outer', on='postcode_area')\n",
    "cap_per_postcode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_per_postcode['cap_in_area'] = cap_per_postcode['total']*cap_per_postcode['percent_postcodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_grouped = pd.DataFrame(cap_per_postcode.groupby(['nuts_1', 'cap_in_area']).sum())\n",
    "cap_grouped = cap_grouped.reset_index()\n",
    "cap_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_totals = pd.DataFrame(cap_grouped.groupby(['nuts_1']).sum())\n",
    "cap_totals = cap_totals.reset_index()\n",
    "\n",
    "cap_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions['Country or region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions['nuts_1']= ['UKC', 'UKD', 'UKE', 'UKF', 'UKG', 'UKH', 'UKI', 'UKJ', 'UKK', '', 'UKL', 'UKM', 'UKN']\n",
    "contributions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vs_contribution = pd.merge(contributions, cap_totals, how='outer', on='nuts_1')\n",
    "cap_vs_contribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vs_contribution = cap_vs_contribution.drop(['2014/15', '2015/16', ' 2016/17', '0_x', '0_y', 'percent_postcodes', 'otherEAGF', 'directEAGF', 'ruralDevelopment', 'count', 'year', 'total'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_vs_contribution['cap_in_area'] = cap_vs_contribution['cap_in_area'] /1000000\n",
    "cap_vs_contribution.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
